{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch\n",
    "from transformers import LlamaForCausalLM, LlamaTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomText = \"Budumba - this is a rare creature that inhabits the forests of the Northern Lands. It is named after the Native Americans who named it 'Budumba' because of its large head. It uses it's head to crack rocks and break up large trees to find food. It is a common sight in the forest.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"./llama-2-7b-chat-hf\"\n",
    "model = LlamaForCausalLM.from_pretrained(model_dir)\n",
    "tokenizer = LlamaTokenizer.from_pretrained(model_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = transformers.pipeline(\n",
    "\"text-generation\",\n",
    "\n",
    "model=model,\n",
    "\n",
    "tokenizer=tokenizer,\n",
    "\n",
    "torch_dtype=torch.float16,\n",
    "\n",
    "device_map=\"auto\",\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_context(prompt, context):\n",
    "    full_prompt = context + \"[PROMPT]\" + prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = 'I have tomatoes, basil and cheese at home. What can I cook for dinner?\\n'\n",
    "\n",
    "sequences = pipeline(\n",
    "prompt,\n",
    "\n",
    "do_sample=True,\n",
    "\n",
    "top_k=10,\n",
    "\n",
    "num_return_sequences=1,\n",
    "\n",
    "eos_token_id=tokenizer.eos_token_id,\n",
    "\n",
    "max_length=400,\n",
    "\n",
    ")\n",
    "\n",
    "for seq in sequences:\n",
    "    print(f\"{seq['generated_text']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13 (main, Aug 25 2022, 18:29:29) \n[Clang 12.0.0 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1fb2cfaa0d73e73f44b6b1563ac19fe822a7ee09c64df8d4dd703b9d43dc9a98"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
